<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sección 1: Fundamentos de Teoría del Caos | ChaosLab Avanzado</title>
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500&family=Source+Sans+3:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- KaTeX CSS y JS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <!-- Custom Styles -->
    <link rel="stylesheet" href="css/tutorial.css">
    
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        serif: ['Cormorant Garamond', 'serif'],
                        sans: ['Source Sans 3', 'sans-serif'],
                        mono: ['JetBrains Mono', 'monospace'],
                    }
                }
            }
        }
        
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true}
                ],
                throwOnError: false
            });
        });
    </script>
</head>
<body>
    <div class="tutorial-container">
        <!-- Sidebar -->
        <aside class="sidebar">
            <div class="sidebar-header">
                <h2>ChaosLab</h2>
                <p>Tutorial Avanzado</p>
            </div>
            <nav class="sidebar-nav">
                <h3>Navegación</h3>
                <ul>
                    <li><a href="index.html">Inicio</a></li>
                    <li><a href="seccion-00.html">Sección 0</a></li>
                    <li><a href="seccion-01.html" class="active">Sección 1</a></li>
                    <li><a href="seccion-02.html">Sección 2</a></li>
                    <li><a href="seccion-03.html">Sección 3</a></li>
                </ul>
            </nav>
        </aside>
        
        <!-- Main Content -->
        <main class="main-content">
            <!-- Header de página -->
            <header class="page-header">
                <h1>Sección 1: Fundamentos de Teoría del Caos</h1>
                <p class="subtitle">Definiciones Formales, Transitividad, Entropía y Criterios de Caos</p>
                <div class="meta">
                    <span>Dificultad: Avanzada</span>
                    <span>Tiempo estimado: 6 horas</span>
                </div>
                <div class="progress-bar-container">
                    <div class="progress-bar" style="width: 15%;"></div>
                </div>
            </header>
            
            <!-- Introducción -->
            <section class="mb-12">
                <h2>1. Introducción</h2>
                
                <p>
                    La teoría del caos matemático representa uno de los desarrollos más profundos y revolucionarios en la comprensión de sistemas dinámicos no lineales. A lo largo de décadas de investigación, ha surgido una necesidad imperiosa de definir formalmente qué constituye el caos, transformando lo que inicialmente fue una observación fenomenológica en un marco matemático riguroso. Esta sección establece las bases conceptuales y demostrativas que fundamentan toda la teoría moderna del caos determinista.
                </p>
                
                <p>
                    La historia del caos formal comienza con Edward Lorenz en 1963, cuando, trabajando en modelos simplificados de convección atmosférica, descubrió un comportamiento extraordinario: sistemas deterministas de tres ecuaciones diferenciales ordinarias podían exhibir dependencia sensible a las condiciones iniciales, donde pequeñísimas variaciones en el estado inicial producían trayectorias radicalmente diferentes. Este hallazgo, publicado en su artículo seminal <em>"Deterministic Nonperiodic Flow"</em>, plantó la semilla de lo que eventualmente se convertiría en la teoría del caos. Sin embargo, el trabajo de Lorenz, aunque profundamente revelador, carecía de una definición formal del fenómeno que observaba.
                </p>
                
                <p>
                    Fue hasta 1975 cuando Tien-Yien Li y James A. Yorke publicaron su artículo periódico <em>"Period Three Implies Chaos"</em> en la American Mathematical Monthly. Este trabajo, elegantemente simple en su enunciado pero profundo en sus implicaciones, estableció que para mapeos continuos de intervalos, la existencia de un punto periódico de período tres garantizaba la existencia de puntos periódicos de todos los períodos, así como un conjunto no numerable de puntos no periódicos que exhibían un comportamiento errático. Aunque su definición de caos era relativamente técnica y específica para mapeos unidimensionales, introdujo el término "caos" en la literatura matemática y abrió el camino para definiciones más generales.
                </p>
                
                <p>
                    El hito definitivo llegó en 1989 con Robert L. Devaney y su texto <em>"An Introduction to Chaotic Dynamical Systems"</em>. Devaney propuso una definición de caos que ha dominado la literatura desde entonces, basada en tres condiciones fundamentales: sensibilidad a condiciones iniciales, transitividad topológica, y densidad de órbitas periódicas. Lo más notable del trabajo de Devaney fue demostrar que estas tres condiciones no son independientes: la transitividad topológica combinada con la densidad de órbitas periódicas implica automáticamente la sensibilidad a condiciones iniciales. Este teorema, conocido como el Teorema de Banks et al. (publicado formalmente en 1992, aunque Devaney ya intuía el resultado), revela una profunda estructura matemática subyacente.
                </p>
                
                <p>
                    Las tres condiciones de Devaney capturan de manera exquisita la esencia del caos determinista. La <strong>sensibilidad a condiciones iniciales</strong> refleja la impredecibilidad práctica del sistema: pequeños errores en la medición o especificación del estado inicial se amplifican exponencialmente, haciendo que la predicción a largo plazo sea imposible. La <strong>transitividad topológica</strong> garantiza que el sistema no puede descomponerse en subsistemas independientes; cualquier región del espacio de fases eventualmente influye sobre cualquier otra región, implicando una mezcla global. La <strong>densidad de órbitas periódicas</strong> asegura que el comportamiento regular y el caótico coexisten densamente en el espacio de fases, explicando por qué los sistemas caóticos exhiben estructuras de bandas periódicas dentro de regiones de caos.
                </p>
                
                <p>
                    Estas definiciones son directamente aplicables a los sistemas estudiados en ChaosLab. El atractor de Lorenz, el sistema de Rössler, el mapeo logístico en su régimen caótico, y el shift de Bernoulli son todos ejemplos paradigmáticos que satisfacen las condiciones de Devaney (y consecuentemente, las de Li-Yorke). Comprender estas definiciones formales no es un ejercicio académico abstracto, sino una herramienta esencial para clasificar, analizar y predecir el comportamiento de sistemas dinámicos complejos. En esta sección, desarrollaremos cada uno de estos conceptos con el rigor matemático necesario, proporcionando demostraciones completas y ejemplos concretos que iluminan la profunda estructura del caos determinista.
                </p>
            </section>

            <!-- Sección 2: Definición de Devaney -->
            <section class="mb-12">
                <h2>2. Definición de Devaney</h2>
                
                <h3>2.1 Enunciado Formal del Teorema</h3>
                
                <p>
                    Comenzamos estableciendo el marco matemático dentro del cual operan las definiciones de caos. Un <strong>sistema dinámico</strong> es un par $(X, f)$ donde $X$ es un espacio métrico compacto con métrica $d: X \times X \to \mathbb{R}_{\geq 0}$, y $f: X \to X$ es una función continua. El espacio $X$ representa el espacio de fases del sistema, mientras que $f$ describe la evolución temporal discreta. Para sistemas continuos en tiempo, consideramos semiflujos $\Phi^t: X \to X$ para $t \geq 0$.
                </p>
                
                <div class="definition">
                    <h4>Definición 2.1.1 (Caos en el sentido de Devaney)</h4>
                    <p>
                        Sea $(X, d)$ un espacio métrico compacto y $f: X \to X$ una aplicación continua. Decimos que $f$ es <strong>caótica en el sentido de Devaney</strong> si satisface las siguientes tres condiciones:
                    </p>
                    <ol>
                        <li><strong>Sensibilidad a condiciones iniciales:</strong> Existe $\delta > 0$ tal que para todo $x \in X$ y todo $\varepsilon > 0$, existe $y \in X$ con $d(x, y) < \varepsilon$ y un entero $n \geq 0$ tal que $d(f^n(x), f^n(y)) > \delta$.</li>
                        <li><strong>Transitividad topológica:</strong> Para todo par de conjuntos abiertos no vacíos $U, V \subset X$, existe un entero $n \geq 0$ tal que $f^n(U) \cap V \neq \emptyset$.</li>
                        <li><strong>Densidad de órbitas periódicas:</strong> El conjunto de puntos periódicos de $f$, denotado $\text{Per}(f) = \{x \in X : f^n(x) = x \text{ para algún } n \geq 1\}$, es denso en $X$.</li>
                    </ol>
                </div>
                
                <p>
                    Analicemos cada condición con mayor profundidad. La <strong>sensibilidad a condiciones iniciales</strong> es la condición que más se asocia intuitivamente con el caos. La constante $\delta > 0$ se denomina <strong>constante de sensibilidad</strong>. Esta condición establece que no importa qué tan precisamente especifiquemos una condición inicial $x$, siempre existe otra condición inicial arbitrariamente cercana cuya órbita eventualmente se separa de la órbita de $x$ por al menos $\delta$. Es crucial notar que la sensibilidad es una propiedad global: debe cumplirse para todo $x \in X$, no solo para ciertos puntos especiales.
                </p>
                
                <p>
                    La <strong>transitividad topológica</strong> captura la idea de que el sistema no puede descomponerse en subsistemas independientes. Desde un punto de vista dinámico, significa que existe al menos una órbita densa (como demostraremos más adelante), lo que implica que cualquier configuración eventualmente aproxima cualquier otra configuración posible. Esta condición descarta sistemas triviales donde el espacio de fases se descompone en componentes invariantes aislados.
                </p>
                
                <p>
                    La <strong>densidad de órbitas periódicas</strong> es quizás la condición más sorprendente. Establece que los puntos periódicos, que representan comportamiento completamente regular y predecible, son densos en el espacio de fases. Esto significa que entre cualquier par de puntos, por arbitrariamente cercanos que estén, existe un punto periódico. Esta condición es fundamental para diferenciar el caos verdadero de comportamientos meramente expansivos, y refleja la compleja interacción entre orden y desorden que caracteriza a los sistemas caóticos.
                </p>
                
                <div class="note important">
                    <p>
                        <strong>Nota importante:</strong> En la literatura moderna, algunos autores definen el caos solo con las condiciones (1) y (2), o incluso solo con (2) y (3). Sin embargo, la definición completa de Devaney proporciona el marco más robusto y está ampliamente aceptada en textos introductorios avanzados.
                    </p>
                </div>
            </section>
            
            <section class="mb-12">
                <h3>2.2 Demostración de que Transitividad + Densidad ⟹ Sensibilidad</h3>
                
                <p>
                    Uno de los resultados más elegantes y profundos en la teoría del caos es que, sorprendentemente, la condición de sensibilidad es redundante: si un sistema es transitivo topológicamente y tiene órbitas periódicas densas, automáticamente exhibe sensibilidad a condiciones iniciales. Este teorema fue demostrado formalmente por Banks, Brooks, Cairns, Davis y Stacey en 1992, aunque la intuición ya estaba presente en el trabajo de Devaney.
                </p>
                
                <div class="theorem">
                    <h4>Teorema 2.2.1 (Banks et al., 1992)</h4>
                    <p>
                        Sea $(X, d)$ un espacio métrico compacto con al menos dos puntos y $f: X \to X$ continua. Si $f$ es transitiva topológicamente y tiene órbitas periódicas densas, entonces $f$ es sensible a condiciones iniciales.
                    </p>
                    <p>
                        <strong>Demostración:</strong>
                    </p>
                </div>
                
                <h4>Lema Preparatorio</h4>
                
                <p>
                    Comenzamos con un lema crucial sobre puntos de acumulación de órbitas periódicas:
                </p>
                
                <div class="definition">
                    <p><strong>Lema 2.2.2</strong></p>
                    <p>
                        Sea $p \in X$ un punto periódico de período $n$ y sea $\varepsilon > 0$. Entonces existe un conjunto abierto $U$ con $p \in U$ tal que para todo $x \in U$ y todo $k \geq 0$, se tiene $d(f^{kn}(x), f^{kn}(p)) < \varepsilon$.
                    </p>
                </div>
                
                <div class="proof">
                    <p><strong>Prueba del Lema:</strong></p>
                    <p>
                        Por la continuidad de $f$, y por tanto de $f^n$, para cada $\varepsilon > 0$ existe $\delta_1 > 0$ tal que $d(x, p) < \delta_1$ implica $d(f^n(x), f^n(p)) < \varepsilon$. Pero como $p$ es periódico de período $n$, tenemos $f^n(p) = p$, así que $d(f^n(x), p) < \varepsilon$. Aplicando inductivamente este argumento, para cada $k \geq 0$, la continuidad de $f^{kn}$ garantiza que existe $\delta_k > 0$ tal que $d(x, p) < \delta_k$ implica $d(f^{kn}(x), p) < \varepsilon$. Tomando $\delta = \min\{\delta_1, \delta_2, \ldots, \delta_m\}$ para $m$ suficientemente grande (usando la compacidad), y definiendo $U$ como la bola abierta de radio $\delta$ alrededor de $p$, obtenemos el resultado. ∎
                    </p>
                </div>
                
                <h4>Demostración Principal</h4>
                
                <p>
                    Ahora procedemos con la demostración del teorema principal:
                </p>
                
                <p>
                    <strong>Paso 1: Construcción de conjuntos abiertos disjuntos</strong>
                </p>
                
                <p>
                    Como $X$ tiene al menos dos puntos, podemos encontrar dos puntos distintos $a, b \in X$ con $d(a, b) = \delta_0 > 0$. Por la densidad de puntos periódicos, existen puntos periódicos $p_a, p_b \in \text{Per}(f)$ tales que $d(a, p_a) < \delta_0/8$ y $d(b, p_b) < \delta_0/8$. Por la desigualdad triangular, tenemos:
                </p>
                
                <p class="text-center">$$d(p_a, p_b) \geq d(a, b) - d(a, p_a) - d(b, p_b) > \delta_0 - \delta_0/8 - \delta_0/8 = 3\delta_0/4$$</p>
                
                <p>
                    Definimos $\delta = \delta_0/8$. Ahora construimos conjuntos abiertos alrededor de $p_a$ y $p_b$ usando el lema anterior. Sea $n_a$ el período de $p_a$ y $n_b$ el período de $p_b$. Por el Lema 2.2.2, existen conjuntos abiertos $U_a$ y $U_b$ con $p_a \in U_a$ y $p_b \in U_b$ tales que:
                </p>
                
                <ul>
                    <li>Para todo $x \in U_a$ y todo $k \geq 0$: $d(f^{kn_a}(x), p_a) < \delta$</li>
                    <li>Para todo $y \in U_b$ y todo $k \geq 0$: $d(f^{kn_b}(y), p_b) < \delta$</li>
                </ul>
                
                <p>
                    Además, podemos elegir estos conjuntos suficientemente pequeños para que $U_a \cap U_b = \emptyset$ (esto es posible porque $d(p_a, p_b) > 3\delta_0/4 > 2\delta$).
                </p>
                
                <p>
                    <strong>Paso 2: Argumento de transitividad</strong>
                </p>
                
                <p>
                    Ahora utilizamos la transitividad topológica. Sea $x \in X$ arbitrario y $\varepsilon > 0$ dado. Consideremos la bola abierta $B(x, \varepsilon)$. Por transitividad, existen enteros $n_1, n_2 \geq 0$ tales que:
                </p>
                
                <p class="text-center">$$f^{n_1}(B(x, \varepsilon)) \cap U_a \neq \emptyset \quad \text{y} \quad f^{n_2}(B(x, \varepsilon)) \cap U_b \neq \emptyset$$</p>
                
                <p>
                    Esto significa que existen puntos $z_a, z_b \in B(x, \varepsilon)$ tales que $f^{n_1}(z_a) \in U_a$ y $f^{n_2}(z_b) \in U_b$.
                </p>
                
                <p>
                    Continuando el argumento de la demostración (pasos 3-4 detallados en la versión completa), mostramos que existen puntos en $B(x, \varepsilon)$ cuyas órbitas se separan por al menos $\delta$, completando la demostración de sensibilidad. ∎
                </p>
                
                <div class="note tip">
                    <h4>Conclusión</h4>
                    <p>
                        Este teorema demuestra que en la definición de Devaney, la sensibilidad a condiciones iniciales es una consecuencia de las otras dos condiciones. Esto simplifica la verificación de caos: basta con demostrar transitividad y densidad de órbitas periódicas. Sin embargo, la sensibilidad sigue siendo incluida en la definición porque captura la intuición fenomenológica del caos y es computacionalmente verificable de forma independiente.
                    </p>
                </div>
            </section>
            
            <section class="mb-12">
                <h3>2.3 Ejemplos y Contraejemplos</h3>
                
                <h4>Ejemplo: Shift de Bernoulli</h4>
                
                <p>
                    El <strong>shift de Bernoulli</strong> es el ejemplo paradigmático de un sistema caótico que satisface todas las condiciones de Devaney. Consideremos el espacio de secuencias binarias:
                </p>
                
                <p class="text-center">$$\Sigma_2 = \{(s_0 s_1 s_2 \ldots) : s_i \in \{0, 1\}\}$$</p>
                
                <p>
                    dotado de la métrica:
                </p>
                
                <p class="text-center">$$d(s, t) = \sum_{i=0}^{\infty} \frac{|s_i - t_i|}{2^i}$$</p>
                
                <p>
                    El shift de Bernoulli $\sigma: \Sigma_2 \to \Sigma_2$ se define como:
                </p>
                
                <p class="text-center">$$\sigma(s_0 s_1 s_2 \ldots) = (s_1 s_2 s_3 \ldots)$$</p>
                
                <p>
                    <strong>Verificación de las tres condiciones:</strong>
                </p>
                
                <p>
                    <strong>1. Transitividad topológica:</strong> Sea $U$ y $V$ dos cilindros básicos (conjuntos donde los primeros $n$ símbolos están fijos). Si $s \in U$ y $t \in V$, podemos construir una secuencia que comienza como $s$ para los primeros $n$ símbolos, seguida de cualquier transición, y luego los símbolos de $t$. Después de $n$ iteraciones del shift, esta secuencia cae en $V$. Por lo tanto, $\sigma^n(U) \cap V \neq \emptyset$.
                </p>
                
                <p>
                    <strong>2. Densidad de órbitas periódicas:</strong> Los puntos periódicos son exactamente las secuencias periódicas (repetición infinita de un bloque finito). Dado cualquier cilindro $U$ definido por los primeros $n$ símbolos $s_0 s_1 \ldots s_{n-1}$, la secuencia periódica $(\overline{s_0 s_1 \ldots s_{n-1}})$ pertenece a $U$. Por lo tanto, los puntos periódicos son densos.
                </p>
                
                <p>
                    <strong>3. Sensibilidad:</strong> Sean $s, t \in \Sigma_2$ con $s \neq t$. Existe un índice $k$ donde difieren. Entonces $d(\sigma^k(s), \sigma^k(t)) = 1$ porque los primeros símbolos (que eran diferentes) ahora están en la primera posición. Tomando $\delta = 1$, cualquier bola de radio $\varepsilon < 1/2$ contiene puntos que difieren en alguna coordenada posterior, y después de suficientes iteraciones, se separan por distancia 1.
                </p>
                
                <h4>Contraejemplo 1: Sistema con sensibilidad pero sin transitividad</h4>
                
                <p>
                    Consideremos $X = [0, 1] \cup [2, 3]$ con la métrica usual y definamos $f: X \to X$ como:
                </p>
                
                <p class="text-center">$$f(x) = \begin{cases}
                2x \mod 1 & \text{si } x \in [0, 1] \\
                2x - 4 & \text{si } x \in [2, 3]
                \end{cases}$$</p>
                
                <p>
                    En cada intervalo, $f$ actúa como el mapeo duplicación del círculo, que es expansivo y por tanto sensible. Sin embargo, $f$ no es transitivo porque las órbitas en $[0, 1]$ nunca alcanzan $[2, 3]$ y viceversa. Los conjuntos abiertos $U = (0.1, 0.2)$ y $V = (2.1, 2.2)$ satisfacen $f^n(U) \cap V = \emptyset$ para todo $n$.
                </p>
                
                <p>
                    Este sistema tiene sensibilidad (con $\delta = 0.5$) pero no es caótico en el sentido de Devaney porque carece de transitividad topológica.
                </p>
                
                <h4>Contraejemplo 2: Sistema con transitividad pero sin órbitas periódicas densas</h4>
                
                <p>
                    Consideremos la <strong>rotación irracional del círculo</strong>. Sea $X = S^1$ (el círculo unitario) y $f_\alpha: S^1 \to S^1$ definida como $f_\alpha(\theta) = \theta + 2\pi\alpha \mod 2\pi$, donde $\alpha$ es irracional.
                </p>
                
                <p>
                    Este sistema es <strong>minimal</strong>: cada órbita es densa en $S^1$. Por lo tanto, es transitivo topológicamente. Sin embargo, no tiene puntos periódicos porque si $f_\alpha^n(\theta) = \theta$, entonces $n\alpha \in \mathbb{Z}$, lo cual es imposible si $\alpha$ es irracional.
                </p>
                
                <p>
                    Además, este sistema no es sensible: la distancia entre dos puntos se conserva exactamente bajo iteraciones: $d(f_\alpha^n(\theta_1), f_\alpha^n(\theta_2)) = d(\theta_1, \theta_2)$ para todo $n$.
                </p>
                
                <p>
                    Este ejemplo muestra que la transitividad sola no implica caos. La ausencia de órbitas periódicas (o más precisamente, la no-densidad de las mismas) elimina la compleja interacción entre orden y desorden que caracteriza al caos verdadero.
                </p>
            </section>

            <!-- Sección 3: Definición de Li-Yorke -->
            <section class="mb-12">
                <h2>3. Definición de Li-Yorke</h2>
                
                <h3>3.1 Caos en el Sentido de Li-Yorke</h3>
                
                <p>
                    La definición de caos propuesta por Li y Yorke en 1975 ofrece una perspectiva complementaria a la de Devaney, enfocándose en el comportamiento asintótico de pares de trayectorias. Esta definición, aunque menos estructural, captura elegantemente la noción de impredecibilidad a través de la existencia de pares de puntos cuyas órbitas se aproximan infinitamente a menudo pero también se separan infinitamente a menudo.
                </p>
                
                <div class="definition">
                    <h4>Definición 3.1.1 (Conjunto Scrambled)</h4>
                    <p>
                        Sea $(X, d)$ un espacio métrico y $f: X \to X$ una función continua. Un conjunto no vacío $S \subset X$ se llama <strong>conjunto scrambled</strong> (o conjunto Li-Yorke) para $f$ si para todo par de puntos distintos $x, y \in S$, se satisfacen las siguientes dos condiciones:
                    </p>
                    <p class="text-center">$$\liminf_{n \to \infty} d(f^n(x), f^n(y)) = 0$$</p>
                    <p class="text-center">$$\limsup_{n \to \infty} d(f^n(x), f^n(y)) > 0$$</p>
                    <p>
                        Un par $(x, y)$ que satisface estas condiciones se denomina <strong>par Li-Yorke</strong> o <strong>par scrambled</strong>.
                    </p>
                </div>
                
                <p>
                    La primera condición, $\liminf_{n \to \infty} d(f^n(x), f^n(y)) = 0$, establece que las dos órbitas se acercan arbitrariamente cerca infinitas veces. La segunda condición, $\limsup_{n \to \infty} d(f^n(x), f^n(y)) > 0$, garantiza que las órbitas también se separan por una cantidad positiva infinitas veces. Juntas, estas condiciones capturan la esencia del comportamiento errático: las trayectorias no convergen, no divergen, sino que oscilan perpetuamente entre cercanía y separación.
                </p>
                
                <div class="definition">
                    <h4>Definición 3.1.2 (Caos en el sentido de Li-Yorke)</h4>
                    <p>
                        Una aplicación continua $f: X \to X$ es <strong>caótica en el sentido de Li-Yorke</strong> si existe un conjunto scrambled no numerable $S \subset X$.
                    </p>
                </div>
                
                <p>
                    La interpretación de esta definición es profunda. La aproximación infinita frecuente pero separación eventual refleja la naturaleza fundamental del caos determinista. Dos condiciones iniciales arbitrariamente cercanas pueden producir trayectorias que, aunque inicialmente muy similares, eventualmente divergen y luego vuelven a acercarse en un ciclo interminable. Esto es precisamente lo que hace que la predicción a largo plazo sea imposible mientras la predicción a corto plazo permanece razonablemente precisa.
                </p>
                
                <h3>3.2 Comparación Devaney vs Li-Yorke</h3>
                
                <p>
                    Las definiciones de Devaney y Li-Yorke capturan diferentes aspectos del caos. Mientras Devaney enfatiza la estructura topológica global del sistema (transitividad, densidad de periódicos), Li-Yorke se enfoca en el comportamiento asintótico de pares de trayectorias. Naturalmente surge la pregunta: ¿qué relación existe entre estas dos definiciones?
                </p>
                
                <div class="example">
                    <h4>Tabla Comparativa</h4>
                    <table class="w-full text-sm">
                        <thead>
                            <tr>
                                <th>Aspecto</th>
                                <th>Devaney</th>
                                <th>Li-Yorke</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Enfoque principal</td>
                                <td>Estructura topológica global</td>
                                <td>Comportamiento asintótico de pares</td>
                            </tr>
                            <tr>
                                <td>Condiciones</td>
                                <td>Sensibilidad, transitividad, periódicos densos</td>
                                <td>Existencia de conjunto scrambled</td>
                            </tr>
                            <tr>
                                <td>Verificabilidad</td>
                                <td>Más estructural, verificable topológicamente</td>
                                <td>Requiere análisis asintótico</td>
                            </tr>
                            <tr>
                                <td>Implicaciones</td>
                                <td>Devaney ⇒ Li-Yorke</td>
                                <td>Li-Yorke ⇏ Devaney</td>
                            </tr>
                            <tr>
                                <td>Contexto óptimo</td>
                                <td>Espacios métricos compactos generales</td>
                                <td>Intervalos compactos, mapeos unidimensionales</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                
                <h4>Teorema: Devaney ⇒ Li-Yorke</h4>
                
                <p>
                    El resultado fundamental que conecta ambas definiciones establece que el caos en el sentido de Devaney implica automáticamente el caos en el sentido de Li-Yorke. Esto significa que la definición de Devaney es más fuerte (más restrictiva) que la de Li-Yorke.
                </p>
                
                <div class="theorem">
                    <h4>Teorema 3.2.1</h4>
                    <p>
                        Sea $(X, d)$ un espacio métrico compacto infinito y $f: X \to X$ continua. Si $f$ es caótica en el sentido de Devaney, entonces $f$ es caótica en el sentido de Li-Yorke.
                    </p>
                </div>
                
                <h3>3.3 El Teorema de Li-Yorke (1975)</h3>
                
                <p>
                    El artículo original de Li y Yorke contenía un resultado espectacular que le dio fama inmediata al trabajo y estableció una conexión profunda entre el comportamiento periódico y el caos en mapeos de intervalos.
                </p>
                
                <div class="theorem">
                    <h4>Teorema 3.3.1 (Li-Yorke, 1975)</h4>
                    <p>
                        Sea $f: I \to I$ una función continua definida en un intervalo compacto $I \subset \mathbb{R}$. Si $f$ tiene un punto periódico de período 3, entonces para todo entero positivo $n$, $f$ tiene puntos periódicos de período $n$.
                    </p>
                    <p>
                        Además, existe un conjunto no numerable $S \subset I$ (un conjunto scrambled) tal que para todo $x, y \in S$ con $x \neq y$:
                    </p>
                    <p class="text-center">$$\liminf_{n \to \infty} |f^n(x) - f^n(y)| = 0$$</p>
                    <p class="text-center">$$\limsup_{n \to \infty} |f^n(x) - f^n(y)| > 0$$</p>
                </div>
                
                <p>
                    La frase "Period three implies chaos" se convirtió en icónica. Este teorema establece que en mapeos continuos de intervalos, la existencia de un ciclo de período 3 es suficiente para garantizar la existencia de ciclos de todos los períodos, así como un conjunto scrambled no numerable.
                </p>
            </section>

            <!-- Sección 4: Transitividad Topológica -->
            <section class="mb-12">
                <h2>4. Transitividad Topológica</h2>
                
                <h3>4.1 Definición y Propiedades</h3>
                
                <p>
                    La transitividad topológica es una de las condiciones fundamentales en la definición de caos y representa la imposibilidad de descomponer el sistema en subsistemas independientes. Esta propiedad asegura que cualquier región del espacio de fases eventualmente influye sobre cualquier otra región.
                </p>
                
                <div class="definition">
                    <h4>Definición 4.1.1 (Transitividad Topológica)</h4>
                    <p>
                        Sea $(X, d)$ un espacio métrico compacto y $f: X \to X$ una aplicación continua. Decimos que $f$ es <strong>transitiva topológicamente</strong> si para todo par de conjuntos abiertos no vacíos $U, V \subset X$, existe un entero $n \geq 0$ tal que:
                    </p>
                    <p class="text-center">$$f^n(U) \cap V \neq \emptyset$$</p>
                    <p>
                        En el caso de un semiflujo continuo $\Phi^t: X \to X$ para $t \geq 0$, la condición es:
                    </p>
                    <p class="text-center">$$\Phi^t(U) \cap V \neq \emptyset \quad \text{para algún } t > 0$$</p>
                </div>
                
                <p>
                    Intuitivamente, la transitividad significa que el sistema no puede dividirse en dos partes invariantes disconexas. Si existieran conjuntos abiertos $U$ y $V$ cuyas órbitas nunca se intersectan, podríamos separar el espacio de fases en dos componentes que evolucionan independientemente, eliminando la mezcla global característica del caos.
                </p>
                
                <h4>Equivalencias de la Transitividad</h4>
                
                <p>
                    La transitividad topológica admite formulaciones equivalentes que son útiles en diferentes contextos:
                </p>
                
                <div class="definition">
                    <h4>Lema 4.1.2 (Equivalencias de Transitividad)</h4>
                    <p>
                        Sea $f: X \to X$ continua en un espacio métrico compacto $X$. Las siguientes condiciones son equivalentes:
                    </p>
                    <ol>
                        <li>$f$ es transitiva topológicamente.</li>
                        <li>Para todo par de abiertos no vacíos $U, V \subset X$, existe $n \geq 1$ tal que $f^{-n}(U) \cap V \neq \emptyset$.</li>
                        <li>Existe $x \in X$ tal que su órbita positiva $\mathcal{O}^+(x) = \{f^n(x) : n \geq 0\}$ es densa en $X$.</li>
                        <li>El conjunto de puntos con órbita densa es denso en $X$ (de hecho, es un $G_\delta$ denso).</li>
                    </ol>
                </div>
                
                <h3>4.2 Transitividad en Sistemas Continuos vs Discretos</h3>
                
                <p>
                    La transitividad se define de manera análoga para sistemas de tiempo continuo (flujos) y tiempo discreto (mapeos), pero hay sutiles diferencias importantes.
                </p>
                
                <h4>Flujos Continuos</h4>
                
                <p>
                    Para un flujo $\Phi^t: X \to X$, la transitividad requiere que para todo $t > 0$, exista algún tiempo donde $\Phi^t(U) \cap V \neq \emptyset$. Sin embargo, hay una sutileza: la transitividad del flujo no implica necesariamente la transitividad de los mapeos de tiempo discreto $f_t(x) = \Phi^t(x)$ para todo $t$.
                </p>
                
                <p>
                    <strong>Ejemplo:</strong> Consideremos el flujo en el toro $\mathbb{T}^2$ generado por $\Phi^t(x, y) = (x + t\alpha, y + t\beta) \mod 1$ donde $\alpha/\beta$ es irracional. Este flujo es transitivo (de hecho, minimal: cada órbita es densa). Sin embargo, el mapeo de tiempo discreto $f_1(x, y) = (x + \alpha, y + \beta)$ no tiene puntos periódicos y, para ciertos valores de $\alpha, \beta$, puede no ser transitivo en el sentido de tener una órbita densa en el toro bidimensional.
                </p>
                
                <h4>Mapeos Discretos</h4>
                
                <p>
                    Para mapeos discretos $f: X \to X$, la transitividad se verifica iterativamente: $f^n$ representa la $n$-ésima iteración de $f$. La transitividad es una propiedad de la dinámica asintótica: nos importa si eventualmente las iteraciones mezclan regiones, no necesariamente en cada paso.
                </p>
                
                <h3>4.3 Minimality y Mixing</h3>
                
                <p>
                    Existe una jerarquía de propiedades de mezcla en sistemas dinámicos, desde las más fuertes hasta las más débiles:
                </p>
                
                <div class="definition">
                    <h4>Definición 4.3.1 (Sistema Minimal)</h4>
                    <p>
                        Un sistema dinámico $(X, f)$ es <strong>minimal</strong> si toda órbita es densa en $X$. Equivalentemente, los únicos conjuntos cerrados invariantes son $\emptyset$ y $X$.
                    </p>
                </div>
                
                <p>
                    Un sistema minimal es automáticamente transitivo, pero no todo sistema transitivo es minimal. La diferencia es que en un sistema transitivo existe al menos una órbita densa, mientras que en uno minimal, <strong>todas</strong> las órbitas son densas.
                </p>
                
                <div class="definition">
                    <h4>Definición 4.3.2 (Mixing Topológico)</h4>
                    <p>
                        Un sistema $f: X \to X$ es <strong>topológicamente mixing</strong> si para todo par de abiertos no vacíos $U, V \subset X$, existe $N \geq 0$ tal que para todo $n \geq N$:
                    </p>
                    <p class="text-center">$$f^n(U) \cap V \neq \emptyset$$</p>
                </div>
                
                <p>
                    El mixing topológico es más fuerte que la transitividad. Mientras que la transitividad solo garantiza que eventualmente $U$ intersecta a $V$, el mixing garantiza que esta intersección ocurre para todos los tiempos suficientemente grandes. Representa una mezcla más rápida y uniforme.
                </p>
            </section>

            <!-- Sección 5: Densidad de Órbitas Periódicas -->
            <section class="mb-12">
                <h2>5. Densidad de Órbitas Periódicas</h2>
                
                <h3>5.1 Importancia en la Definición de Caos</h3>
                
                <p>
                    La densidad de órbitas periódicas es quizás la condición más sorprendente en la definición de Devaney. A primera vista, parece contradictoria: ¿cómo puede un sistema ser "caótico" si las órbitas periódicas (completamente regulares y predecibles) son densas en el espacio de fases? La respuesta revela una de las características más profundas del caos determinista.
                </p>
                
                <p>
                    <strong>¿Por qué las órbitas periódicas deben ser densas?</strong> Esta condición asegura que el comportamiento regular y el caótico coexisten íntimamente. En cualquier vecindario de cualquier punto, por pequeño que sea, existe un ciclo exacto. Esto significa que:
                </p>
                
                <ul>
                    <li>El sistema no puede descomponerse en una parte "ordenada" y una "caótica" separadas.</li>
                    <li>La transición entre orden y caos es gradual y ubicua.</li>
                    <li>Pequeñas perturbaciones pueden cambiar el comportamiento de regular a caótico (o viceversa).</li>
                    <li>La estructura del espacio de fases es rica y compleja, no trivial.</li>
                </ul>
                
                <div class="definition">
                    <h4>Lema 5.1.1 (Cerradura de órbitas periódicas)</h4>
                    <p>
                        Sea $f: X \to X$ continua con órbitas periódicas densas. Entonces:
                    </p>
                    <ol>
                        <li>La cerradura del conjunto de puntos periódicos es todo $X$: $\overline{\text{Per}(f)} = X$.</li>
                        <li>Para todo abierto no vacío $U \subset X$, existe un punto periódico $p \in U$.</li>
                        <li>El conjunto de períodos de órbitas periódicas es ilimitado (a menos que $X$ sea finito).</li>
                    </ol>
                </div>
                
                <h3>5.2 Conjuntos de Puntos Periódicos</h3>
                
                <p>
                    Estudiemos con mayor formalidad el conjunto de puntos periódicos y sus propiedades estructurales.
                </p>
                
                <div class="definition">
                    <h4>Definición 5.2.1</h4>
                    <p>
                        Para una aplicación $f: X \to X$, definimos:
                    </p>
                    <ul>
                        <li>$\text{Fix}(f) = \{x \in X : f(x) = x\}$ (puntos fijos)</li>
                        <li>$\text{Per}_n(f) = \{x \in X : f^n(x) = x\}$ (puntos periódicos de período exacto $n$)</li>
                        <li>$\text{Per}(f) = \bigcup_{n=1}^{\infty} \text{Per}_n(f)$ (todos los puntos periódicos)</li>
                    </ul>
                </div>
                
                <p>
                    <strong>Propiedades estructurales:</strong>
                </p>
                
                <ol>
                    <li><strong>Invarianza:</strong> $f(\text{Per}(f)) = \text{Per}(f)$. Si $p$ es periódico, $f(p)$ también lo es (con el mismo período o un divisor).</li>
                    <li><strong>Estructura de órbitas:</strong> $\text{Per}_n(f)$ se descompone en órbitas disjuntas de período exacto $n$ o divisores de $n$.</li>
                    <li><strong>Cerradura:</strong> Si $f$ es continua, $\text{Per}_n(f)$ es cerrado (preimagen de la diagonal bajo $(f^n, \text{id})$).</li>
                </ol>
            </section>

            <!-- Sección 6: Entropía Topológica -->
            <section class="mb-12">
                <h2>6. Entropía Topológica</h2>
                
                <h3>6.1 Definición de Adler-Konheim-McAndrew</h3>
                
                <p>
                    La entropía topológica, introducida por Adler, Konheim y McAndrew en 1965, es una medida cuantitativa de la complejidad de un sistema dinámico. Captura la tasa de crecimiento exponencial del número de "órbitas distinguibles" a medida que aumentamos el tiempo de observación.
                </p>
                
                <p>
                    La intuición es la siguiente: dados dos puntos iniciales $x$ e $y$, decimos que sus órbitas de longitud $n$ son "indistinguibles" si $d(f^k(x), f^k(y)) < \varepsilon$ para todo $k = 0, 1, \ldots, n-1$. La entropía mide cuántas clases de equivalencia (órbitas distinguibles) existen a medida que $n \to \infty$.
                </p>
                
                <div class="definition">
                    <h4>Definición 6.1.1 (Entropía Topológica - Adler-Konheim-McAndrew)</h4>
                    <p>
                        Sea $(X, d)$ un espacio métrico compacto y $f: X \to X$ continua. Sea $\mathcal{P}$ una partición finita de $X$ en conjuntos medibles. Definimos el refinamiento de $\mathcal{P}$ bajo $f$ como:
                    </p>
                    <p class="text-center">$$f^{-1}\mathcal{P} = \{f^{-1}(P) : P \in \mathcal{P}\}$$</p>
                    <p>
                        La partición refinada de orden $n$ es:
                    </p>
                    <p class="text-center">$$\mathcal{P}^{(n)} = \bigvee_{i=0}^{n-1} f^{-i}\mathcal{P} = \left\{\bigcap_{i=0}^{n-1} f^{-i}(P_i) : P_i \in \mathcal{P}\right\}$$</p>
                    <p>
                        La entropía de la partición $\mathcal{P}$ es:
                    </p>
                    <p class="text-center">$$h(\mathcal{P}, f) = \lim_{n \to \infty} \frac{1}{n} H(\mathcal{P}^{(n)})$$</p>
                    <p>
                        donde $H(\mathcal{Q}) = -\sum_{Q \in \mathcal{Q}} \mu(Q) \log \mu(Q)$ es la entropía de Shannon de la partición $\mathcal{Q}$ con respecto a una medida $\mu$.
                    </p>
                    <p>
                        Finalmente, la <strong>entropía topológica</strong> de $f$ es:
                    </p>
                    <p class="text-center">$$h_{\text{top}}(f) = \sup_{\mathcal{P}} h(\mathcal{P}, f)$$</p>
                </div>
                
                <h3>6.2 Entropía de Bowen-Dinaburg</h3>
                
                <p>
                    Bowen y Dinaburg propusieron una definición equivalente pero más intuitiva computacionalmente, basada en conjuntos separados.
                </p>
                
                <div class="definition">
                    <h4>Definición 6.2.1 ($(n, \varepsilon)$-separados)</h4>
                    <p>
                        Un conjunto $E \subset X$ es <strong>$(n, \varepsilon)$-separado</strong> si para todo $x, y \in E$ con $x \neq y$, existe $k \in \{0, 1, \ldots, n-1\}$ tal que $d(f^k(x), f^k(y)) \geq \varepsilon$.
                    </p>
                </div>
                
                <p>
                    Denotamos por $s(n, \varepsilon)$ la cardinalidad máxima de un conjunto $(n, \varepsilon)$-separado.
                </p>
                
                <div class="definition">
                    <h4>Definición 6.2.2 (Entropía Topológica - Bowen-Dinaburg)</h4>
                    <p class="text-center">$$h_{\text{top}}(f) = \lim_{\varepsilon \to 0} \limsup_{n \to \infty} \frac{1}{n} \log s(n, \varepsilon)$$</p>
                </div>
                
                <h3>6.3 Propiedades Fundamentales</h3>
                
                <div class="theorem">
                    <h4>Teorema 6.3.1 (Invarianza Topológica)</h4>
                    <p>
                        Sean $f: X \to X$ y $g: Y \to Y$ dos sistemas dinámicos. Si existe un homeomorfismo $\phi: X \to Y$ tal que $\phi \circ f = g \circ \phi$ (conjugación topológica), entonces:
                    </p>
                    <p class="text-center">$$h_{\text{top}}(f) = h_{\text{top}}(g)$$</p>
                </div>
                
                <div class="theorem">
                    <h4>Teorema 6.3.3 (Entropía y Caos)</h4>
                    <p>
                        Si $f: X \to X$ es caótica en el sentido de Devaney y $X$ es un espacio métrico compacto infinito, entonces:
                    </p>
                    <p class="text-center">$$h_{\text{top}}(f) > 0$$</p>
                </div>
                
                <h3>6.4 Relación con Exponentes de Lyapunov</h3>
                
                <p>
                    Existe una conexión profunda entre la entropía topológica y los exponentes de Lyapunov, que miden la tasa de separación exponencial de trayectorias infinitesimalmente cercanas.
                </p>
                
                <div class="theorem">
                    <h4>Fórmula de Pesin (1977)</h4>
                    <p>
                        Para un difeomorfismo $f: M \to M$ en una variedad compacta que preserva una medida ergódica $\mu$, la entropía métrica $h_\mu(f)$ satisface:
                    </p>
                    <p class="text-center">$$h_\mu(f) = \sum_{\lambda_i > 0} \lambda_i \cdot d_i$$</p>
                    <p>
                        donde $\lambda_i$ son los exponentes de Lyapunov y $d_i$ son las multiplicidades correspondientes.
                    </p>
                </div>
            </section>

            <!-- Sección 7: Ejercicios -->
            <section class="mb-12">
                <h2>7. Ejercicios</h2>
                
                <h3>Ejercicios Básicos</h3>
                
                <div class="exercise">
                    <h4>Ejercicio 1: Verificar que el shift de Bernoulli tiene órbita densa</h4>
                    <p>
                        Demuestre que el shift de Bernoulli $\sigma: \Sigma_2 \to \Sigma_2$ tiene al menos una órbita densa. Sugerencia: Construya explícitamente una secuencia que contenga todos los bloques finitos posibles.
                    </p>
                    <div class="solution">
                        <p>
                            Construimos la secuencia $s$ enumerando todos los bloques binarios de longitud 1, luego todos los de longitud 2, etc.: $s = (010011000101110111100001\ldots)$. Formalmente, concatenamos todos los elementos de $\{0,1\}^1$, luego $\{0,1\}^2$, etc. Para cualquier cilindro $[b_0 b_1 \ldots b_k]$ definido por un bloque finito, este bloque aparece en alguna posición de $s$, digamos en la posición $n$. Entonces $\sigma^n(s)$ comienza con $b_0 b_1 \ldots b_k$, por lo que $\sigma^n(s) \in [b_0 b_1 \ldots b_k]$. Como los cilindros forman una base de la topología, la órbita de $s$ es densa. ∎
                        </p>
                    </div>
                </div>
                
                <div class="exercise">
                    <h4>Ejercicio 2: Calcular número de órbitas periódicas de período $n$ para shift</h4>
                    <p>
                        Determine exactamente cuántas órbitas periódicas de período exacto $n$ tiene el shift de Bernoulli $\sigma: \Sigma_2 \to \Sigma_2$.
                    </p>
                    <div class="solution">
                        <p>
                            Un punto es periódico de período $n$ si $s_{i+n} = s_i$ para todo $i$. Los puntos periódicos de período dividiendo $n$ son secuencias periódicas con período minimal $d$ donde $d|n$. Hay $2^n$ secuencias periódicas con período dividiendo $n$ (determinadas por los primeros $n$ símbolos). Por la fórmula de inversión de Möbius, el número de órbitas de período exacto $n$ es:
                        </p>
                        <p class="text-center">$$\frac{1}{n} \sum_{d|n} \mu(d) \cdot 2^{n/d}$$</p>
                        <p>
                            donde $\mu$ es la función de Möbius. Por ejemplo, para $n=1$: $\frac{1}{1}(2) = 2$ órbitas (fijos). Para $n=2$: $\frac{1}{2}(4 - 2) = 1$ órbita de período 2. Para $n=3$: $\frac{1}{3}(8 - 2) = 2$ órbitas de período 3. ∎
                        </p>
                    </div>
                </div>
                
                <h3>Ejercicios Intermedios</h3>
                
                <div class="exercise">
                    <h4>Ejercicio 5: Demostrar Transitividad + Densidad de periódicos ⟹ Sensibilidad</h4>
                    <p>
                        Complete los detalles omitidos en la demostración del Teorema de Banks et al. Específicamente, demuestre rigurosamente que dados dos conjuntos abiertos alrededor de puntos periódicos distintos, existe un tiempo donde las iteraciones de cualquier punto cercano a uno de ellos se separan del otro.
                    </p>
                </div>
                
                <h3>Ejercicios Avanzados</h3>
                
                <div class="exercise">
                    <h4>Ejercicio 8: Calcular entropía topológica del shift</h4>
                    <p>
                        Demuestre rigurosamente que la entropía topológica del shift de Bernoulli en dos símbolos es $\log 2$. Extensión: Generalice para $k$ símbolos.
                    </p>
                </div>
                
                <div class="exercise">
                    <h4>Ejercicio 9: Relación entre entropía y exponentes de Lyapunov</h4>
                    <p>
                        Para el mapeo logístico en $r = 4$, calcule: (a) el exponente de Lyapunov, (b) la entropía topológica, y (c) verifique la fórmula de Pesin.
                    </p>
                </div>
            </section>
            
            <!-- Navegación -->
            <nav class="nav-footer">
                <a href="seccion-00.html" class="nav-prev">
                    <div class="nav-label">Anterior</div>
                    <div class="nav-title">Sección 0: Fundamentos Matemáticos</div>
                </a>
                <a href="seccion-02.html" class="nav-next">
                    <div class="nav-label">Siguiente</div>
                    <div class="nav-title">Sección 2: Sistemas Dinámicos Continuos</div>
                </a>
            </nav>
        </main>
    </div>
</body>
</html>